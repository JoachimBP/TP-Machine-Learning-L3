{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04899fa6",
   "metadata": {},
   "source": [
    "# TP 5 - Régression logistique et classification\n",
    "\n",
    "Machine Learning L3 -\n",
    "Université Paul Sabatier\n",
    "\n",
    "Joachim Bona-Pellissier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885e6f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "from sklearn import linear_model, datasets, decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6744f43",
   "metadata": {},
   "source": [
    "## 1 - Introduction au problème"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8e818c",
   "metadata": {},
   "source": [
    "On va travailler avec le dataset `breast_cancer`. Ce dataset contient des données médicales prélevées sur $n$ patientes du Wisconsin, USA ayant une masse suspecte dans le sein. Ces données sont issues d'une imagerie appliquée sur chaque masse, dans le but de déterminer si elle est cancéreuse ou non. De chaque imagerie on tire ainsi $d$ features, qui sont des nombres réels positifs. On n'a donc ici que des variables quantitatives. \n",
    "\n",
    "Ensuite, à chaque patiente correspond une classe (ou label) égale à $0$ si la masse est maligne (cancéreuse) et $1$ si elle est bénigne. Le but est d'apprendre à l'aide de ces données un algorithme capable de prédire en fonction des $d$ features si une masse mammaire est maligne ou bénigne. Il s'agit donc d'un problème de classification binaire.\n",
    "\n",
    "On commence par télécharger le dataset à l'aide de scikit-learn. On stocke les features dans une dataframe pandas `X` et les labels dans une série `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2293cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "breast_cancer = sk.datasets.load_breast_cancer(as_frame=True)\n",
    "\n",
    "X = breast_cancer.data\n",
    "y = breast_cancer.target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b985d66f",
   "metadata": {},
   "source": [
    "a) Que valent le nombre d'échantillons $n$ et la dimension $d$ du problème d'apprentissage ? On pourra les obtenir à partir de `X`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee452995",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "006f0043",
   "metadata": {},
   "source": [
    "Le nombre d'échantillons $n$ est égal à ...\n",
    "\n",
    "La dimension $d$ est égale à ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4733d586",
   "metadata": {},
   "source": [
    "b) Afficher les 5 premières lignes de `X`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9104fc21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d04893ba",
   "metadata": {},
   "source": [
    "c) Pour se faire une première idée du dataset, on va visualiser la répartition des classes. Afficher l'histogramme des classes à l'aide de la méthode `hist`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266bb02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313a303f",
   "metadata": {},
   "source": [
    "Un des points clés en machine learning est d'être capable de mesurer les performances de nos modèles. Pour cela, on va séparer notre ensemble entre un ensemble d'apprentissage `X_train, y_train` et un ensemble de test `X_test, y_test` dont on ne se servira par pour l'apprentissage et sur lequel on évaluera notre modèle.\n",
    "\n",
    "d) Utiliser la fonction `train_test_split` de sklearn pour séparer le dataset enre un train et un test set. On prendra ici une taille de test set égale à 20% de l'échantillon total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c31b273",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = ...\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703770fd",
   "metadata": {},
   "source": [
    "e) Afficher les histogrammes du train et du test set (si possible sur une même figure). La répartition des classes doit être équivalente entre le train et le test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93441f5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c237852a",
   "metadata": {},
   "source": [
    "## 2 - Introduction à la régression logistique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372f21db",
   "metadata": {},
   "source": [
    "On va utiliser un algorithme classique de machine learning en classification, la régression logistique. \n",
    "\n",
    "En régression logistique, on cherche à assigner à chaque échantillon $x$ une probabilité $p(x) \\in [0,1]$, qui va être la probabilité que la classe soit égale à $1$ (ici probabilité que la masse soit bénigne). Pour obtenir des probabilités, on se sert de la fonction [sigmoïde](https://fr.wikipedia.org/wiki/Sigmo%C3%AFde_(math%C3%A9matiques)) :\n",
    "\n",
    "$$\\sigma(t) = \\frac{1}{1 + e^{-t}}.$$\n",
    "\n",
    "Cette fonction prend des valeurs entre $0$ et $1$ et a en fait les propriétés d'une fonction de répartition.\n",
    "\n",
    "Notons $d$ la dimension du problème. En régression logistique, on calcule un vecteur $\\beta \\in \\mathbb{R}^d$ et un biais $a \\in \\mathbb{R}$ et on exprime la probabilité d'être dans la classe $1$ pour un échantillon $x$ comme \n",
    "\n",
    "$$p(x) = \\sigma(\\beta^Tx + a) = \\sigma( \\beta_1 x_1 + \\dots + \\beta_d x_d + a). $$\n",
    "\n",
    "Le classifieur correspondant est alors\n",
    "\n",
    "$$ \\hat{y} (x) = \\begin{cases} 1 & \\text{si } p(x) \\geq 1/2 \\\\ 0 & \\text{si } p(x) < 1/2. \\end{cases} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3db6f54",
   "metadata": {},
   "source": [
    "a) Quelle est la nature géométrique de la frontière qui sépare les échantillons de $\\mathbb{R}^d$ classifiés comme $0$ et ceux classifiés comme $1$ par le classifieur $\\hat{y}$ ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45966ef1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2a68365e",
   "metadata": {},
   "source": [
    "Entraîner un classifieur par régression logistique, c'est donc déterminer les paramètres $\\beta, a \\in \\mathbb{R}^d \\times \\mathbb{R}$. On ne rentrera pas dans ce TP dans les détails de l'apprentissage, scikit-learn va le faire pour nous. Ce qu'il faut savoir est que $\\beta,a$ sont obtenus en définissant une fonction de perte, et en utilisant ensuite un algorithme d'optimisation pour minimiser cette fonction de perte. \n",
    "\n",
    "b) Créer un classifieur `lr` par régression logistique, et l'entraîner sur les données `X_train, y_train`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e2e26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1db62f1",
   "metadata": {},
   "source": [
    "## 3 - Evaluation des performances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae378f5",
   "metadata": {},
   "source": [
    "Maintenant qu'on a entraîné le classifieur `lr`, on va le tester et l'évaluer. \n",
    "\n",
    "a) Utiliser `lr` pour prédire un vecteur de classes `y_pred` à partir de l'ensemble de test `X_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a590cee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d280c130",
   "metadata": {},
   "source": [
    "Pour mesurer les performances du classifieur, on va comparer les classes prédites `y_pred` aux classes réelles `y_test`. Une mesure simple et naturelle est le taux d'erreur, c'est-à-dire la proportion d'échantillons $i$ pour lesquels `y_pred[i] != y_test[i]`. \n",
    "\n",
    "Remarque : ici `y_pred` va avoir le format d'un array numpy et `y_test` celui d'une série pandas. C'est donc plutôt `y_pred[i]` et `np.array(y_test)[i]` qu'on va comparer.\n",
    "\n",
    "b) Calculer le taux d'erreur (le faire **à la main** et sans utiliser les fonctions toutes faites de scikit-learn)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1d0251",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "706ebcd1",
   "metadata": {},
   "source": [
    "En machine learning, on utilise souvent l'accuracy, qui correspond plutôt au taux de succès.\n",
    "\n",
    "c) Afficher l'accuracy de la prédiction (**à la main** encore une fois)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6443bd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "befe0d0c",
   "metadata": {},
   "source": [
    "Normalement, la plupart des échantillons ont été correctement classifiés. Cependant, l'évaluation par taux d'erreur/accuracy ne permet pas de savoir si les erreurs viennent d'échantillons $0$ classés comme $1$ ou d'échantillons $1$ classés comme $0$. Dans notre exemple de diagnostic du cancer du sein, c'est une nuance importante car il peut être plus grave de diagnostiquer une tumeur cancéreuse comme bénigne que l'inverse.\n",
    "\n",
    "Une manière de visualiser cela est la matrice de confusion. Il s'agit d'une matrice carrée avec autant de lignes/colonnes que de classes (2 dans notre cas). Pour la ligne correspondant à la classe $i$, l'entrée $j$ contient le nombre d'échantillons dont la vraie classe est $i$ qui ont été classifiés comme $j$ par notre classifieur.\n",
    "\n",
    "d) Construire **à la main** la matrice de confusion de notre prédiction, la stocker dans une dataframe et l'afficher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9206b176",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "851aedc7",
   "metadata": {},
   "source": [
    "## 4 - PCA et visualisation du dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678180d8",
   "metadata": {},
   "source": [
    "On va maintenant chercher à visualiser le dataset. Pour pouvoir afficher les échantillons sur un plan, on va réduire les dimensions des échantillons de 30 à 2. Pour cela, on va se servir de l'analyse en composantes principales (PCA). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68cdcb60",
   "metadata": {},
   "source": [
    "a) Calculer un vecteur `X_train_pca` contenant les 2 composantes principales des données d'entraînement `X_train`. On se servira de la fonction PCA de scikit-learn. En utilisant la méthode `transform` de cette même pca, transformer `X_test` pour obtenir `X_test_pca`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04688d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4075b0f",
   "metadata": {},
   "source": [
    "b) Créer un graphique représentant les exemples du train set en fonction de leurs composantes principales. Toutes les données doivent être de la même taille, représentées par un même symbole. \n",
    "Colorer en vert les échantillons bénins et en rouge les échantillons malins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef04ba58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple de graphique avec plt.scatter\n",
    "\n",
    "from random import randint\n",
    "x = [randint (0, 10) for i in range(10)]\n",
    "y = [randint (5, 20) for i in range(10)]\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "plt.scatter(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06b5ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Premier graphique\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43bdb3b9",
   "metadata": {},
   "source": [
    "c) On veut maintenant identifier les données de `X_test` qui sont mal prédites.\n",
    "Refaites le même graphique en affichant cette fois les éléments de `X_test_pca` et en colorant les exemples en fonction de leur classe (comme précédemment). Cette fois-ci, vous indiquez les exemples mal classés en utilisant une forme particulière (à vous de choisir quelque chose de joli, qui se voit et qui se comprend au premier coup d'œil). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55717f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemples mal classés\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e093a1c3",
   "metadata": {},
   "source": [
    "d) Où semblent se trouver les points mal classifiés ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5113ceff",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d730dd",
   "metadata": {},
   "source": [
    "La regression logistique estime la probabilité d'appartenance d'une donnée à chacune des classes. Cette probabilité donne une information quant à l'incertitude de cette prédiction. Pour une donnée, si toutes les probabilités sont faibles sauf une qui est presqu'égale à 1, alors la classe est (presque) certaine. Au contraire, pour certaines données, des probabilités significativement différentes de 0 et de 1 sont estimées ; dans ce cas, la prédiction de la classe est incertaine.\n",
    "Ici, on dit que si une probabilité est < 0,9 ou > 0,1, alors la classe prédite pour cette donnée est incertaine.\n",
    "\n",
    "\n",
    "e) Refaites le même graphique que précédemment. Cette fois-ci vous indiquez les exemples dont la classe est incertaine par une couleur, une taille ou une forme particulière (à votre choix, du moment que l'on voit et comprend au premier coup d'œil). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8088479",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Affichage de la confiance de prédiction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d6a5ea",
   "metadata": {},
   "source": [
    "f) Où se situent les points pour lesquels la prédiction est incertaine ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb00aa3c",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9fc791",
   "metadata": {},
   "source": [
    "## 5 - Comparaison avec d'autres algorithmes de classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877c7cd2",
   "metadata": {},
   "source": [
    "On veut maintenant comparer notre prédiction par régression linéaire aux prédiction obtenues avec d'autres méthodes de classification. \n",
    "\n",
    "a) Entraîner un classifieur `knn` par k plus proches voisins et un classifieur `tree` par arbre binaire de décision sur les données `X_train, y_train`. On laissera les paramètres par défaut donnés par scikit-learn. Calculer les prédictions de ces deux classifieurs sur `X_test` et les mettre dans des vecteurs `y_pred_knn` et `y_pred_tree`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bec9878",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b40b08",
   "metadata": {},
   "source": [
    "b) Pour les prédictions `y_pred_knn` et `y_pred_tree`, calculer le taux d'erreur et l'accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a34524",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "050f9c6f",
   "metadata": {},
   "source": [
    "c) Calculer la matrice de confusion pour ces deux prédictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fcc2ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7d9b56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3755cb33",
   "metadata": {},
   "source": [
    "d) Comparer brièvement les performances des trois classifieurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52496b51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "262f00ac",
   "metadata": {},
   "source": [
    "Bonus : e) Le nombre d'erreurs faites par les algorithmes est-il la seule chose qui permet de préférer un algorithme à d'autres ? Quels autre critères peuvent nous pousser à choisir un algorithme plutôt qu'un autre ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f67dad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8d3213c2",
   "metadata": {},
   "source": [
    "## 6 - Visualisation des frontières de décision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79e7a79",
   "metadata": {},
   "source": [
    "Pour se faire une intuition des frontières de décision des différents types d'algorithmes, on va reprendre la PCA effectuée plus tôt et entraîner les modèles cette fois sur les 2 composantes principales `X_train_pca`. Attention, ce n'est donc pas la frontière de décision des algorithmes entraînés plus haut (en dimension 30) qu'on va visualiser, mais celles d'algorithmes entraînés en dimension 2.\n",
    "\n",
    "a) Entraîner un classifieur par régression logistique `lr_pca` sur les données `X_train_pca, y_train`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313377dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6c9fdbfa",
   "metadata": {},
   "source": [
    "Le code suivant devrait afficher les zones classifiées comme $0$ et $1$ par `lr_pca`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cae9889",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lr_pca\n",
    "\n",
    "# Code issu d'un TP de Philippe Preux\n",
    "\n",
    "\n",
    "h = 10  # pas de la grille\n",
    "x_min = X_train_pca[:,0].min() - 50\n",
    "x_max = X_train_pca[:,0].max() + 50\n",
    "y_min = X_train_pca[:,1].min() - 50\n",
    "y_max = X_train_pca[:,1].max() + 50\n",
    "xx, yy = np.meshgrid (np.arange (x_min, x_max, h), np.arange (y_min, y_max, h))\n",
    "# la grille est créée. Les coordonnées des intersections sont dans xx et yy\n",
    "\n",
    "# on utilise ce modèle pour prédire la classe de chacun des exemples\n",
    "Z2d = model. predict (np.c_[xx.ravel(), yy.ravel()])\n",
    "# et on fait la figure\n",
    "Z2d = Z2d. reshape (xx. shape)\n",
    "plt. figure ()\n",
    "plt. pcolormesh (xx, yy, Z2d, cmap=plt.cm.Paired)\n",
    "# On définit la couleur des points\n",
    "color = y_train\n",
    "dcol = {0:'r', 1:'g'}\n",
    "color = color.replace(dcol)\n",
    "# On affiche les points\n",
    "plt.scatter(X_train_pca[:,0], X_train_pca[:,1], c = color)\n",
    "plt. show ()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2163eaae",
   "metadata": {},
   "source": [
    "b) Entraîner un classifieur par k plus proches voisins `knn_pca` sur `X_train_pca, y_train`. Reprendre le code ci-dessus pour afficher les zones de décision dans le cas de `knn_pca`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b40d495",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e496facb",
   "metadata": {},
   "source": [
    "c) Entraîner un classifieur par arbre de décision `tree_pca` sur `X_train_pca, y_train`. A nouveau afficher les zones de décision dans le cas de `tree_pca`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d186495",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2e7417f9",
   "metadata": {},
   "source": [
    "d) Commenter la nature des zones pour les différents classifieurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1a8c27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "17b89081",
   "metadata": {},
   "source": [
    "Bonus : S'il vous reste du temps, recommencer avec d'autres classifieurs de scikit-learn (naive bayes ou svm linéaire par exemple)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca8adff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
