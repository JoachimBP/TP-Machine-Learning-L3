{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c00fa53",
   "metadata": {},
   "source": [
    "# TP 7 - SVM linéaire et validation croisée\n",
    "\n",
    "**L’objectif** de cette séance de travaux pratiques est de montrer l’utilisation des techniques de validation croisée pour l’évaluation et la comparaison de modèles décisionnels, ainsi que des méthodes de recherche de valeurs pour les hyper-paramètres (comme le coefficient de régularisation)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1581bc23",
   "metadata": {},
   "source": [
    "## 1 - Estimation des performances par validation croisée\n",
    "\n",
    "Afin d’illustrer l’utilisation de la validation croisée, nous considérons un problème de classification sur le dataset Iris. Pour rappel, celui-ci consiste à identifier à quelle espèce appartient une plante parmi trois possibilités (*Iris Setosa*, *Iris Virginica* et *Iris Versicolor*) à partir de la longueur et la largeur des sépales et des pétales.\n",
    "\n",
    "Nous employons des perceptrons multi-couches (PMC) avec une seule couche cachée de 100 neurones et une valeur $ \\alpha = 1 $ pour la constante de régularisation (pondération du terme d’oubli ou *weight decay*). Il n’est pas indispensable pour cette séance de savoir en détails comment fonctionnent ces réseaux de neurones.\n",
    "\n",
    "La validation croisée sera utilisée pour estimer les performances de généralisation *à partir de l’ensemble d’apprentissage*. Ensuite, cette estimation sera comparée à l’estimation obtenue sur l’ensemble de test que nous avions mis de côté au départ. Les explications sur la validation croisée et sa mise en œuvre dans Scikit-learn se trouvent [dans la documentation](http://scikit-learn.org/stable/modules/cross_validation.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838734f0",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "# importations\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "\n",
    "# chargement du jeu de données Iris\n",
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "data, labels = iris.data, iris.target\n",
    "\n",
    "# découpage initial en données d'apprentissage et données de test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49540dc",
   "metadata": {},
   "source": [
    "La fonction train_test_split de scikit-learn nous permet de diviser aléatoirement le jeu de données en deux partitions train (apprentissage) et test (évaluation) selon des proportions arbitraires.\n",
    "\n",
    "Comme d’habitude, il est intéressant de visualiser les données à notre disposition. Nous pouvons construire les nuages de points en deux dimensions à l’aide de Matplotlib :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0edab3",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16, 12))\n",
    "n_features = data.shape[-1]\n",
    "n_plots = 6\n",
    "idx = 1\n",
    "cmp = np.array(['r', 'g', 'b'])\n",
    "for dim1 in range(0, n_features):\n",
    "    for dim2 in range(dim1+1, n_features):\n",
    "        fig.add_subplot(2, n_plots // 2, idx)\n",
    "        plt.scatter(X_train[:, dim1], X_train[:, dim2],c=cmp[y_train], s=50, edgecolors='none')\n",
    "        plt.scatter(X_test[:,  dim1], X_test[:, dim2], c='none',  s=50, edgecolors=cmp[y_test])\n",
    "        plt.xlabel(iris.feature_names[dim1])\n",
    "        plt.ylabel(iris.feature_names[dim2])\n",
    "        idx += 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7087f28",
   "metadata": {},
   "source": [
    "## Question\n",
    "\n",
    "Pourquoi a-t-on six nuages de points différents ? Que représente chaque figure ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d004640",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a53305",
   "metadata": {},
   "source": [
    "Pour ce problème de classement, nous allons utiliser un perceptron multi-couches (MLP) avec les valeurs par défaut proposés par scikit-learn pour le nombre de couches (1) et de neurones (100)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b21164",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "# emploi de PMC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "clf = MLPClassifier(solver='lbfgs', alpha=1, tol=5e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7aa50ae",
   "metadata": {},
   "source": [
    "Pour estimer l’erreur de généralisation, nous allons utiliser la validation croisée *K-fold*. Cela va nous permettre d’ajuster, si besoin, les hyperparamètres du modèle décisionnel. scikit-learn implémente diverses stratégies de validation croisée dans le module sklearn.model_selection. Commençons par expérimenter avec l’approche *K-fold*. L’objet KFold dispose d’une méthode .split() qui permet de générer les listes des indices des observations à utiliser pour le sous-jeu d’apprentissage et pour le sous-jeu de *validation*. Plus de détails sur cet objet se trouvent dans la [documentation de K-Fold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04f4636",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "# KFold pour différentes valeurs de k\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# valeurs de k\n",
    "n_folds = np.array([2, 3, 5, 7, 10, 13, 16])\n",
    "\n",
    "# préparation des listes pour stocker les résultats\n",
    "cv_scores = []\n",
    "cv_scores_std = []\n",
    "\n",
    "for k in n_folds:    # pour chaque valeur de k\n",
    "    kf = KFold(n_splits=k)\n",
    "    scores = []\n",
    "    # apprentissage puis évaluation d'un modèle sur chaque split\n",
    "    for train_idx, val_idx in kf.split(X_train):\n",
    "        # apprentissage avec .fit()\n",
    "        clf.fit(X_train[train_idx], y_train[train_idx])\n",
    "        scores.append(clf.score(X_train[val_idx], y_train[val_idx]))\n",
    "    # calcul de la moyenne et de l'écart-type des performances obtenues\n",
    "    cv_scores.append(np.mean(scores))\n",
    "    cv_scores_std.append(np.std(scores))\n",
    "\n",
    "cv_scores, cv_scores_std = np.array(cv_scores), np.array(cv_scores_std)\n",
    "\n",
    "# affichage performance moyenne +- 1 écart-type pour chaque k\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(n_folds, cv_scores, 'b')\n",
    "plt.fill_between(n_folds, cv_scores + cv_scores_std, cv_scores - cv_scores_std, alpha=0.5)\n",
    "plt.xlabel(\"Valeur de $k$ du K-Fold\")\n",
    "plt.ylabel(\"Score moyen\")\n",
    "plt.xlim(2, max(n_folds))\n",
    "plt.xticks(n_folds)\n",
    "plt.title(\"Erreur de généralisation estimée en fonction de $k$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c4d6da",
   "metadata": {},
   "source": [
    "## Question :\n",
    "\n",
    "Que constatez-vous en examinant ce graphique ? Ajoutez des valeurs pour *k* (par ex. 20, 40...) et affichez de nouveau le graphique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72df28f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "09afdd3f",
   "metadata": {},
   "source": [
    "## Question :\n",
    "\n",
    "Pour chaque modèle appris par validation croisée *k-fold*, ajoutez son évaluation sur les données de test mises de côté au départ `X_test, y_test`. Affichez les courbes sur le même graphique. Que constatez-vous ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168c166f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "811885bb",
   "metadata": {},
   "source": [
    "## Question :\n",
    "\n",
    "Réalisez l’estimation des performances en utilisant la [validation croisée leave one out (LOO)](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.LeaveOneOut.html#sklearn.model_selection.LeaveOneOut). Que constatez-vous en comparant les résultats de *k-fold* et de *leave one out* ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512f4d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    "loo = LeaveOneOut()\n",
    "\n",
    "\n",
    "scores = []\n",
    "test_scores = []\n",
    "# apprentissage puis évaluation d'un modèle sur chaque split\n",
    "for train_idx, val_idx in loo.split(X_train):\n",
    "    ...\n",
    "# calcul de la moyenne et de l'écart-type des performances obtenues\n",
    "mean_score = ...\n",
    "std_score = ...\n",
    "test_score = ...\n",
    "\n",
    "print('loo_score =', mean_score\n",
    "print('loo_std =', std_score)\n",
    "print('test_score =', test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd8695a",
   "metadata": {},
   "source": [
    "## Note\n",
    "\n",
    "Pour l’illustration, nous avons itéré ici manuellement à l’aide des itérateurs KFold et LeaveOneOut. Toutefois il est possible d’automatiser ce procédé dans le cas du *KFold* à l’aide de la fonction cross_val_score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9344d9",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "clf = MLPClassifier(solver='lbfgs', alpha=1, tol=5e-3)\n",
    "\n",
    "# Cross-validation KFold avec k=5\n",
    "scores = cross_val_score(clf, X_train, y_train, cv=5)\n",
    "\n",
    "print('Scores de validation avec k=5 : ', scores)\n",
    "print('Score moyen : ', np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97c71af",
   "metadata": {},
   "source": [
    "\n",
    "Cette fonction prend des paramètres supplémentaires (métriques, parallélisation, etc.) qui sont décrites dans [sa documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a29ccc",
   "metadata": {},
   "source": [
    "\n",
    "<a id='chap-tpsvmlineaires'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b39e3e",
   "metadata": {},
   "source": [
    "# 2 - SVM linéaires\n",
    "\n",
    "\n",
    "L’objectif est d’illustration l’utilisation des machines à vecteurs de support  (*Support Vector Machines*, SVM) pour les problèmes de classification linéaires en python avec Scikit-learn.\n",
    "\n",
    "Références externes utiles :\n",
    "\n",
    "> - [Documentation NumPy](https://docs.scipy.org/doc/numpy/user/index.html)  \n",
    "- [Documentation SciPy](https://docs.scipy.org/doc/scipy/reference/)  \n",
    "- [Documentation MatPlotLib](http://matplotlib.org/)  \n",
    "- [Site scikit-learn](http://scikit-learn.org/stable/index.html)  \n",
    "- [Site langage python](https://www.python.org)  \n",
    "- [Site LibSVM](https://www.csie.ntu.edu.tw/~cjlin/libsvm/)  \n",
    "- [Site LibLinear](https://www.csie.ntu.edu.tw/~cjlin/liblinear/)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25598f7",
   "metadata": {},
   "source": [
    "## Machines à vecteurs de support linéaires\n",
    "\n",
    "Les machines à vecteurs de support (SVM : *Support Vector Machines*) sont une classe de méthodes d’apprentissage statistique basées sur le principe de la maximisation de la marge (séparation des classes). Il existe plusieurs formulations (linéaires, versions à noyaux) qui peuvent s’appliquer sur des données séparables (linéairement) mais aussi sur des données non séparables.\n",
    "\n",
    "Les avantages des SVM :\n",
    "\n",
    "- Très efficaces en dimension élevée.  \n",
    "- Ils sont aussi efficaces dans le cas où la dimension de l’espace est plus grande que le nombre d’échantillons d’apprentissage.  \n",
    "- Pour la décision, n’utilisent pas tous les échantillons d’apprentissage, mais seulement une partie (les vecteurs de support). En conséquence, ces algorithmes demandent moins de mémoire.  \n",
    "\n",
    "\n",
    "Désavantages :\n",
    "\n",
    "- Si le nombre d’attributs est beaucoup plus grand que le nombre d’échantillons, les performances sont moins bonnes.  \n",
    "- Comme il s’agit de méthodes de discrimination entre les classes, elles ne fournissent pas d’estimations de probabilités.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd2a790",
   "metadata": {},
   "source": [
    "On continue avec le dataset iris. Pour commencer, nous ne conservons que les deux premiers attributs du jeu de données :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438b31b3",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "X, y = iris.data[:, :2], iris.target\n",
    "# On conserve 50% du jeu de données pour l'évaluation\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbce8f62",
   "metadata": {},
   "source": [
    "Nous pouvons maintenant entraîner une machine à vecteur de support linéaire :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d968300d",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "C = 1.0 # paramètre de régularisation\n",
    "lin_svc = svm.LinearSVC(C=C)\n",
    "lin_svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9913e379",
   "metadata": {},
   "source": [
    "## Question\n",
    "\n",
    "Calculez le score d’échantillons bien classifiés sur le jeu de données de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9288c6",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7663ec25",
   "metadata": {},
   "source": [
    "Visualisons maintenant la surface de décision apprise par notre modèle :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bb397f",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "# Créer la surface de décision discretisée\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "# Pour afficher la surface de décision on va discrétiser l'espace avec un pas h\n",
    "h = max((x_max - x_min) / 100, (y_max - y_min) / 100)\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "\n",
    "# Surface de décision\n",
    "Z = lin_svc.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "plt.contourf(xx, yy, Z, cmap=plt.cm.coolwarm, alpha=0.8)\n",
    "# Afficher aussi les points d'apprentissage\n",
    "plt.scatter(X_train[:, 0], X_train[:, 1], label=\"train\", edgecolors='k', c=y_train, cmap=plt.cm.coolwarm)\n",
    "plt.scatter(X_test[:, 0], X_test[:, 1], label=\"test\", marker='*', c=y_test, cmap=plt.cm.coolwarm)\n",
    "plt.xlabel('Sepal length')\n",
    "plt.ylabel('Sepal width')\n",
    "plt.title(\"LinearSVC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f4e42f",
   "metadata": {},
   "source": [
    "## Question :\n",
    "\n",
    "Afficher de nouveau les frontières de décision en testant différentes valeurs pour le paramètre C. Comment la frontière de décision évolue en fonction de C ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a35cf98",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1d5f7b93",
   "metadata": {},
   "source": [
    "## Question\n",
    "\n",
    "On va maintenant utiliser la validation croisée pour tester différentes valeurs du paramètre `C`. La fonction `GridSearchCV` de scikit-learn va s'occuper de tester les différentes valeurs pour nous. Afficher les scores de validation obtenus pour les différentes valeurs de `C`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50285694",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {'C':[1,3,5,10,20,50,100,1000]}\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e47bc12",
   "metadata": {},
   "source": [
    "## Question\n",
    "\n",
    "D’après la visualisation des frontières de décision, ce modèle vous paraît-il adapté au problème ? Si non, que peut-on faire pour l’améliorer ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1251f17",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587cc6e1",
   "metadata": {},
   "source": [
    "Pour l’instant, nous n’avons exploité que deux variables explicatives. Néanmoins, l’intérêt des machines à vecteur de support linéaires est qu’il est souvent plus facile de trouver des hyperplans séparateurs dans des espaces de grande dimension."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6eea630",
   "metadata": {},
   "source": [
    "## Question\n",
    "\n",
    "Réalisez l’optimisation d’une nouvelle machine à vecteur de support linéaire mais en utilisant les quatre attributs du jeu de données Iris. Le score de classification en test a-t-il augmenté ? Pourquoi ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4312448",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "C = 1\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf062aef",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a70346c",
   "metadata": {},
   "source": [
    "## 3 - Jeu de données Digits\n",
    "\n",
    "Le jeu de données Digits est une collection d’images de chiffres manuscrits. Elles peuvent se charger directement depuis scikit-learn :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb9fb06",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()\n",
    "X, y = digits.data, digits.target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922a5cbf",
   "metadata": {},
   "source": [
    "## Question :\n",
    "\n",
    "Utilisez les données Digits pour construire un classifieur LinearSVC et évaluez-le. Si le temps d’apprentissage est trop long, sélectionnez une partie plus petite de la base d’apprentissage (par exemple 10000 échantillons). Pour quelle valeur de C on obtient le meilleurs résultats de généralisation ? Utiliser la validation croisée avec `GridSearchCV`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc37814",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "date": 1667580335.5931969,
  "filename": "tpSVMLineaires.rst",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "title": "Travaux pratiques - SVM linéaires"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
